{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3473cc19",
   "metadata": {},
   "source": [
    "### Gender prediction with classification method\n",
    "For the model_gender_classification, we've tailored a convolutional neural network (CNN) to distinguish between male and female subjects. This model leverages a custom architecture, beginning with a base of pretrained layers for feature extraction, followed by additional dense layers for refined learning. These layers collectively enhance the model's ability to accurately classify gender based on facial features. The use of a data generator here, as with age regression, ensures efficient handling of large datasets, allowing for dynamic data augmentation and streamlined model training without excessive memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2cfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import SpatialDropout2D, SeparableConv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81090b0f",
   "metadata": {},
   "source": [
    "For managing large datasets efficiently and minimizing memory usage, we utilize data generators. These generators stream data in batches directly to the model during training, enabling real-time data augmentation and improving model performance without overwhelming system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a70b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generator method\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, load_from, batch_size=32, dim=(224,224), n_channels=3,\n",
    "                 shuffle=True, preprocessing=None):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.load_from = load_from\n",
    "        self.preprocessing = preprocessing\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Generates data containing batch_size samples\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            img_path = os.path.join(self.load_from, ID)\n",
    "            img = load_img(img_path, target_size=self.dim)  # This is a PIL image\n",
    "            img = img_to_array(img)  # Convert to numpy array\n",
    "            img = self.preprocessing(img) if self.preprocessing else img  # Apply preprocessing\n",
    "            X[i,] = img\n",
    "\n",
    "            label = ID.split('_')[1]\n",
    "            y[i] = int(label)\n",
    "\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe07cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data gen config\n",
    "load_from_train = 'data/train/'\n",
    "load_from_val = 'data/test/'\n",
    "\n",
    "def preprocess_input_vggface(x):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    x[..., 0] -= 93.5940  # Subtract the mean red value\n",
    "    x[..., 1] -= 104.7624 # Subtract the mean green value\n",
    "    x[..., 2] -= 129.1863 # Subtract the mean blue value\n",
    "    return x\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16\n",
    "params = {'dim': (224, 224),\n",
    "          'batch_size': batch_size,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'preprocessing': preprocess_input_vggface}\n",
    "\n",
    "ids_train = os.listdir(load_from_train) # IDs for training\n",
    "ids_val = os.listdir(load_from_val) # IDs for validation\n",
    "\n",
    "training_generator = DataGenerator(list_IDs = ids_train, load_from = load_from_train, **params)\n",
    "validation_generator = DataGenerator(list_IDs = ids_val, load_from = load_from_val, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14c477",
   "metadata": {},
   "source": [
    "### Build the model with VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596c91b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load VGGFace model\n",
    "# Creating a base model with SENet50\n",
    "base_model = VGGFace(model='senet50', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output    \n",
    "# First block\n",
    "x = BatchNormalization()(x)\n",
    "x = SpatialDropout2D(0.5)(x)\n",
    "x = SeparableConv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "# Removed MaxPooling2D layer here to prevent dimensionality issues\n",
    "\n",
    "# Second block, adjust similarly as needed\n",
    "x = BatchNormalization()(x)\n",
    "x = SpatialDropout2D(0.5)(x)\n",
    "x = SeparableConv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "\n",
    "\n",
    "# Fully connected system\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AlphaDropout(0.5)(x)  # Make sure to call AlphaDropout on `x`\n",
    "x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# Output layer\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Make sure to call this layer on `x`\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Adjust the learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)  # Lower learning rate\n",
    "\n",
    "# Compile the model with the new optimizer\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b942452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "os.makedirs('saved_models0', exist_ok=True)\n",
    "filename = 'saved_models0/-{epoch:02d}---{val_loss:.4f}-{val_accuracy:.4f}---{loss:.4f}-{accuracy:.4f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filename, monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_accuracy', factor=0.8, patience=4, verbose=1, mode='auto', min_delta=0.0001, min_lr=0.0001)\n",
    "callbacks_list = [checkpoint, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8080b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1185/1185 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.8326\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92990, saving model to saved_models0\\-01---0.2235-0.9299---0.3716-0.8326.h5\n",
      "1185/1185 [==============================] - 363s 298ms/step - loss: 0.3716 - accuracy: 0.8326 - val_loss: 0.2235 - val_accuracy: 0.9299 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      " 965/1185 [=======================>......] - ETA: 54s - loss: 0.2437 - accuracy: 0.9051"
     ]
    }
   ],
   "source": [
    "# Fit the model using the Dataset\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30,\n",
    "    callbacks = callbacks_list\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
