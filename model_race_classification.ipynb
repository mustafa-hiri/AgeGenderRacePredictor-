{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50107cab",
   "metadata": {},
   "source": [
    "### Race prediction with classification method\n",
    "Our race classification model is designed with inclusivity at its core, capable of distinguishing among five distinct racial categories: White, Black, Asian, Indian, and Others. This classification framework allows for a broad understanding of diversity, ensuring that our technology can recognize and appreciate the rich variety of human features across different ethnic backgrounds. By training our model on a diverse dataset, we ensure it's equipped to identify these categories with precision, making it a powerful tool for applications requiring nuanced understanding of racial characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2cfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import SpatialDropout2D, SeparableConv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302576f",
   "metadata": {},
   "source": [
    "For managing large datasets efficiently and minimizing memory usage, we utilize data generators. These generators stream data in batches directly to the model during training, enabling real-time data augmentation and improving model performance without overwhelming system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a70b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generator method\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, load_from, batch_size=32, dim=(224,224), n_channels=3,\n",
    "                 shuffle=True, preprocessing=None):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.load_from = load_from\n",
    "        self.preprocessing = preprocessing\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, 5), dtype=int)  # Assuming 5 classes and one-hot encoding is needed\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            img_path = os.path.join(self.load_from, ID)\n",
    "            img = load_img(img_path, target_size=self.dim)\n",
    "            img = img_to_array(img)\n",
    "            img = self.preprocessing(img) if self.preprocessing else img\n",
    "            X[i,] = img\n",
    "\n",
    "            # Extracting the label assuming it's in the 3rd part of the filename after splitting\n",
    "            # Adjust the index according to the actual position of the label in your filenames\n",
    "            label_part = ID.split('_')[2]  # This needs to match your filename structure\n",
    "            try:\n",
    "                label = int(label_part)  # Make sure this part is correctly convertible to an integer\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting label to int for ID: {ID} - Error: {e}\")\n",
    "                continue  # Skip this sample or handle error as appropriate\n",
    "\n",
    "            y[i] = to_categorical(label, num_classes=5)\n",
    "\n",
    "        return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe07cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data gen config\n",
    "load_from_train = 'data/train_race/'\n",
    "load_from_val = 'data/test/'\n",
    "\n",
    "def preprocess_input_vggface(x):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    x[..., 0] -= 93.5940  # Subtract the mean red value\n",
    "    x[..., 1] -= 104.7624 # Subtract the mean green value\n",
    "    x[..., 2] -= 129.1863 # Subtract the mean blue value\n",
    "    return x\n",
    "\n",
    "# Parameters\n",
    "batch_size = 20\n",
    "params = {'dim': (224, 224),\n",
    "          'batch_size': batch_size,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'preprocessing': preprocess_input_vggface}\n",
    "\n",
    "ids_train = os.listdir(load_from_train) # IDs for training\n",
    "ids_val = os.listdir(load_from_val) # IDs for validation\n",
    "\n",
    "training_generator = DataGenerator(list_IDs = ids_train, load_from = load_from_train, **params)\n",
    "validation_generator = DataGenerator(list_IDs = ids_val, load_from = load_from_val, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb9341",
   "metadata": {},
   "source": [
    "### Build the model with VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596c91b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load VGGFace model\n",
    "base_model = VGGFace(model='senet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "# Unfreeze the last convolutional layer\n",
    "base_model.layers[-2].trainable = True\n",
    "\n",
    "# Fully connected system\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Output layer for 4-class classification\n",
    "predictions = Dense(5, activation='softmax')(x)  # Use softmax for multi-class classification\n",
    "\n",
    "# This is the model we will train for classification\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model for classification\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b942452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "os.makedirs('saved_models_race', exist_ok=True)\n",
    "filename = 'saved_models_race/-{epoch:02d}---{val_loss:.4f}-{val_accuracy:.4f}---{loss:.4f}-{accuracy:.4f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filename, monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_accuracy', factor=0.8, patience=4, verbose=1, mode='auto', min_delta=0.0001, min_lr=0.0001)\n",
    "callbacks_list = [checkpoint, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8080b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9822\n",
      "Epoch 1: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 220s 232ms/step - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.8451 - val_accuracy: 0.8249 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9808\n",
      "Epoch 2: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 221s 234ms/step - loss: 0.0648 - accuracy: 0.9808 - val_loss: 0.8959 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9839\n",
      "Epoch 3: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 220s 232ms/step - loss: 0.0525 - accuracy: 0.9839 - val_loss: 0.8301 - val_accuracy: 0.8165 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9841\n",
      "Epoch 4: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 221s 233ms/step - loss: 0.0547 - accuracy: 0.9841 - val_loss: 0.8968 - val_accuracy: 0.8181 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9843\n",
      "Epoch 5: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 0.9058 - val_accuracy: 0.8129 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9806\n",
      "Epoch 6: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 216s 228ms/step - loss: 0.0620 - accuracy: 0.9806 - val_loss: 1.0507 - val_accuracy: 0.7842 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9854\n",
      "Epoch 7: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 216s 228ms/step - loss: 0.0518 - accuracy: 0.9854 - val_loss: 0.8728 - val_accuracy: 0.8310 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9866\n",
      "Epoch 8: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 216s 228ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.8921 - val_accuracy: 0.8262 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9857\n",
      "Epoch 9: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 221s 233ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.9191 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9862\n",
      "Epoch 10: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 220s 233ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.8555 - val_accuracy: 0.8251 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9864\n",
      "Epoch 11: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 221s 233ms/step - loss: 0.0417 - accuracy: 0.9864 - val_loss: 0.9307 - val_accuracy: 0.8141 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9839\n",
      "Epoch 12: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 221s 233ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.9496 - val_accuracy: 0.8124 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9870\n",
      "Epoch 13: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 218s 230ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.8883 - val_accuracy: 0.8255 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9883\n",
      "Epoch 14: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 216s 228ms/step - loss: 0.0376 - accuracy: 0.9883 - val_loss: 1.0994 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9885\n",
      "Epoch 15: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 220s 232ms/step - loss: 0.0397 - accuracy: 0.9885 - val_loss: 0.9846 - val_accuracy: 0.8015 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9854\n",
      "Epoch 16: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 220s 232ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 1.0385 - val_accuracy: 0.8184 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9897\n",
      "Epoch 17: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 220s 232ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.9471 - val_accuracy: 0.8224 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9862\n",
      "Epoch 18: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 220s 232ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.9074 - val_accuracy: 0.8226 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9902\n",
      "Epoch 19: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.9805 - val_accuracy: 0.8255 - lr: 1.0000e-04\n",
      "Epoch 20/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9909\n",
      "Epoch 20: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 1.0432 - val_accuracy: 0.8101 - lr: 1.0000e-04\n",
      "Epoch 21/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9888\n",
      "Epoch 21: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 216s 228ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 1.0641 - val_accuracy: 0.8044 - lr: 1.0000e-04\n",
      "Epoch 22/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9872\n",
      "Epoch 22: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 216s 228ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 1.0137 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 23/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9883\n",
      "Epoch 23: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.9775 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 24/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9883\n",
      "Epoch 24: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.9210 - val_accuracy: 0.8287 - lr: 1.0000e-04\n",
      "Epoch 25/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9897\n",
      "Epoch 25: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 231s 243ms/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.9626 - val_accuracy: 0.8162 - lr: 1.0000e-04\n",
      "Epoch 26/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9891\n",
      "Epoch 26: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 218s 230ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.9700 - val_accuracy: 0.8281 - lr: 1.0000e-04\n",
      "Epoch 27/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9890\n",
      "Epoch 27: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 1.0133 - val_accuracy: 0.8278 - lr: 1.0000e-04\n",
      "Epoch 28/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9892\n",
      "Epoch 28: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.9669 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 29/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9897\n",
      "Epoch 29: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 1.0305 - val_accuracy: 0.8112 - lr: 1.0000e-04\n",
      "Epoch 30/30\n",
      "948/948 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9907\n",
      "Epoch 30: val_accuracy did not improve from 0.83776\n",
      "948/948 [==============================] - 217s 229ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 1.0108 - val_accuracy: 0.8243 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using the Dataset\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30,\n",
    "    callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
